{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(D):\n",
    "    \"\"\"\n",
    "    Given a list of documents, where each document is represented as\n",
    "    a list of tokens, return the resulting vocabulary. The vocabulary\n",
    "    should be a set of tokens which appear more than once in the entire\n",
    "    document collection plus the \"<unk>\" token.\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    token_dict = {}\n",
    "    for document in D:\n",
    "        for word in document:           \n",
    "            token_dict[word] = token_dict.get(word, 0) + 1\n",
    "    for key, value in token_dict.items():\n",
    "        if value > 1:\n",
    "            lst.append(key)\n",
    "                \n",
    "    lst.append(\"<unk>\")\n",
    "    voca_set = set(lst)\n",
    "    \n",
    "    return voca_set\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBoWFeaturizer(object):\n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and the vocabulary\n",
    "        as a set of tokens, compute the binary bag-of-words feature representation.\n",
    "        This function should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        token_dict = {}\n",
    "        \n",
    "        for word in doc:\n",
    "            # if the token is in vocab\n",
    "            if word in vocab:\n",
    "                token_dict[word] = 1\n",
    "            # if there is an unknown token\n",
    "            else:\n",
    "                token_dict[\"<unk>\"] = 1\n",
    "        \n",
    "        return token_dict\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBoWFeaturizer(object):\n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and the vocabulary\n",
    "        as a set of tokens, compute the count bag-of-words feature representation.\n",
    "        This function should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        token_dict = {}\n",
    "        \n",
    "        for word in doc:\n",
    "            if word in vocab:\n",
    "                token_dict[word] = token_dict.get(word, 0) + 1\n",
    "            else:\n",
    "                token_dict[\"<unk>\"] = token_dict.get(\"<unk>\", 0) + 1\n",
    "                \n",
    "        return token_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(D, vocab):\n",
    "    \"\"\"\n",
    "    Given a list of documents D and the vocabulary as a set of tokens,\n",
    "    where each document is represented as a list of tokens, return the IDF scores\n",
    "    for every token in the vocab. The IDFs should be represented as a dictionary that\n",
    "    maps from the token to the IDF value. If a token is not present in the\n",
    "    vocab, it should be mapped to \"<unk>\".\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    D_len = len(D)\n",
    "    idf_dict = {}\n",
    "    \n",
    "   \n",
    "    # loop through all documents\n",
    "    for d in D:\n",
    "        token_seen = set()\n",
    "        for token in d:\n",
    "            if token in vocab:\n",
    "                word = token\n",
    "            else:\n",
    "                word = '<unk>'\n",
    "            if word not in token_seen:\n",
    "                token_seen.add(word)\n",
    "                idf_dict[word] = idf_dict.get(word, 0) + 1\n",
    "    \n",
    "    for token in idf_dict.keys():\n",
    "        idf_dict[token] = numpy.log(D_len / idf_dict[token])\n",
    "  \n",
    "    return idf_dict\n",
    "            \n",
    "            \n",
    "    \n",
    "class TFIDFFeaturizer(object):\n",
    "    def __init__(self, idf):\n",
    "        \"\"\"The idf scores computed via `compute_idf`.\"\"\"\n",
    "        self.idf = idf\n",
    "    \n",
    "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
    "        \"\"\"\n",
    "        Given a document represented as a list of tokens and\n",
    "        the vocabulary as a set of tokens, compute\n",
    "        the TF-IDF feature representation. This function\n",
    "        should return a dictionary which maps from the name of the\n",
    "        feature to the value of that feature.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        # compute tf\n",
    "        tf_dict = {}        \n",
    "        for word in doc:\n",
    "            if word in vocab:\n",
    "                tf_dict[word] = tf_dict.get(word, 0) + 1\n",
    "            else:\n",
    "                tf_dict[\"<unk>\"] = tf_dict.get(\"<unk>\", 0) + 1\n",
    "                \n",
    "        # tf_idf\n",
    "        tf_idf = {}\n",
    "        for token in tf_dict.keys():\n",
    "            tf_idf[token] = tf_dict[token] * self.idf[token]\n",
    "        \n",
    "        \n",
    "        return tf_idf\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not need to edit this cell\n",
    "def load_dataset(file_path):\n",
    "    D = []\n",
    "    y = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            instance = json.loads(line)\n",
    "            D.append(instance['document'])\n",
    "            y.append(instance['label'])\n",
    "    return D, y\n",
    "\n",
    "def convert_to_features(D, featurizer, vocab):\n",
    "    X = []\n",
    "    for doc in D:\n",
    "        X.append(featurizer.convert_document_to_feature_dictionary(doc, vocab))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X, y, k, vocab):\n",
    "    \"\"\"\n",
    "    Computes the statistics for the Naive Bayes classifier.\n",
    "    X is a list of feature representations, where each representation\n",
    "    is a dictionary that maps from the feature name to the value.\n",
    "    y is a list of integers that represent the labels.\n",
    "    k is a float which is the smoothing parameters.\n",
    "    vocab is the set of vocabulary tokens.\n",
    "    \n",
    "    Returns two values:\n",
    "        p_y: A dictionary from the label to the corresponding p(y) score\n",
    "        p_v_y: A nested dictionary where the outer dictionary's key is\n",
    "            the label and the innner dictionary maps from a feature\n",
    "            to the probability p(v|y). For example, `p_v_y[1][\"hello\"]`\n",
    "            should be p(v=\"hello\"|y=1).\n",
    "    \"\"\"\n",
    "    # TODO \n",
    "    num = len(y) # total number of instances\n",
    "    p_y = {} # return dic_1\n",
    "    p_v_y = {} # return dic_2\n",
    "    num_label = {} # count the number of times each label appears, such as: 0, 1\n",
    "    docum_label = {} # for one token - over all the documents in the training data has label y\n",
    "    vocub_label = {} # for all token - over all the words in the vocabulary\n",
    "    \n",
    "    # loop through the whole X dataset\n",
    "    for i in range(num):\n",
    "        # accumulate the number of each label\n",
    "        num_label[y[i]] = num_label.get(y[i], 0) + 1\n",
    "        # assign a new dic(token: value_total) as value in docum_label\n",
    "        docum_label[y[i]] = docum_label.get(y[i], {})\n",
    "        # loop through the X, each dic contains features and corresponding value\n",
    "        for token in X[i]:\n",
    "            # accumulate by both label and token \n",
    "            docum_label[y[i]][token] = docum_label[y[i]].get(token, 0) + X[i][token]\n",
    "            # accumulate only by label(because this is sum of all words)\n",
    "            vocub_label[y[i]] = vocub_label.get(y[i], 0) + X[i][token]\n",
    "    \n",
    "    # calculate the p_v\n",
    "    for label, count in num_label.items():\n",
    "        p_y[label] = count / num\n",
    "        \n",
    "    # calculate the p_v_y\n",
    "    for label, features in docum_label.items():\n",
    "        p_v_y[label] = p_v_y.get(label, {})\n",
    "        # loop the word in the vocabulary\n",
    "        for word in vocab:\n",
    "            # if current word with this current label exists document\n",
    "            if word in features:\n",
    "                p_v_y[label][word] = (k + features[word]) / (k * len(vocab) + vocub_label[label])\n",
    "            # if not\n",
    "            else:\n",
    "                p_v_y[label][word] = k / (k * len(vocab) + vocub_label[label])\n",
    "                \n",
    "    return p_y, p_v_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(D, p_y, p_v_y):\n",
    "    \"\"\"\n",
    "    Runs the prediction rule for Naive Bayes. D is a list of documents,\n",
    "    where each document is a list of tokens.\n",
    "    p_y and p_v_y are output from `train_naive_bayes`.\n",
    "    \n",
    "    Note that any token which is not in p_v_y should be mapped to\n",
    "    \"<unk>\". Further, the input dictionaries are probabilities. You\n",
    "    should convert them to log-probabilities while you compute\n",
    "    the Naive Bayes prediction rule to prevent underflow errors.\n",
    "    \n",
    "    Returns two values:\n",
    "        predictions: A list of integer labels, one for each document,\n",
    "            that is the predicted label for each instance.\n",
    "        confidences: A list of floats, one for each document, that is\n",
    "            p(y|d) for the corresponding label that is returned.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    # loop through the documents\n",
    "    for d in D:\n",
    "        # set variables\n",
    "        p_d = 0\n",
    "        max_label = None\n",
    "        max_p = None\n",
    "        # get the prob of each label\n",
    "        for label, features in p_v_y.items():\n",
    "            # p_y\n",
    "            p_sum = numpy.log(p_y[label])\n",
    "            # p_y + sum of (p_v_y) in current label\n",
    "            for token in d:\n",
    "                # token in p_v_y\n",
    "                if token in p_v_y[label]:\n",
    "                    p_sum += numpy.log(p_v_y[label][token])\n",
    "                # token not in p_v_y\n",
    "                else:\n",
    "                    p_sum += numpy.log(p_v_y[label][\"<unk>\"])\n",
    "            # p_d = p_d_v for all labels (sum of situations when label =0 or 1)\n",
    "            p_d += numpy.exp(p_sum)\n",
    "            # find the label with max p (since p_d is equal, only compare sum)\n",
    "            if not max_p or p_sum > max_p:\n",
    "                max_label = label\n",
    "                max_p = p_sum\n",
    "        # add to corresponding list\n",
    "        predictions.append(max_label)\n",
    "        if p_d == 0:\n",
    "            confidences.append(1)\n",
    "        else:\n",
    "            confidences.append(numpy.exp(max_p)/p_d)\n",
    "                    \n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, k, vocab, mode):\n",
    "    \"\"\"\n",
    "    Trains the Naive Bayes classifier using the semi-supervised algorithm.\n",
    "    \n",
    "    X_sup: A list of the featurized supervised documents.\n",
    "    y_sup: A list of the corresponding supervised labels.\n",
    "    D_unsup: The unsupervised documents.\n",
    "    X_unsup: The unsupervised document representations. # after 1,2,3 method converting (BBoW, CCoW, tfodf)\n",
    "    D_valid: The validation documents.\n",
    "    y_valid: The validation labels.\n",
    "    k: The smoothing parameter for Naive Bayes.\n",
    "    vocab: The vocabulary as a set of tokens.\n",
    "    mode: either \"threshold\" or \"top-k\", depending on which selection\n",
    "        algorithm should be used.\n",
    "    \n",
    "    Returns the final p_y and p_v_y (see `train_naive_bayes`) after the\n",
    "    algorithm terminates.    \n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    X_initial = X_sup\n",
    "    y_initial = y_sup\n",
    "        \n",
    "    # train the model\n",
    "    p_y, p_v_y = train_naive_bayes(X_initial, y_initial, k, vocab)\n",
    "    predictions, confidences = predict_naive_bayes(D_valid, p_y, p_v_y)\n",
    "    initial_accuracy = accuracy_score(y_valid, predictions)\n",
    "    print(\"initial accuracy for valid : \" + str(initial_accuracy))\n",
    "\n",
    "    # do the fliter operation\n",
    "\n",
    "    # threshold\n",
    "    if mode == \"threshold\":\n",
    "        len_new = 0\n",
    "        len_old = 1\n",
    "        while len_new != len_old:         \n",
    "            len_old = len(X_initial)\n",
    "            p_y, p_v_y = train_naive_bayes(X_initial, y_initial, k, vocab)\n",
    "            predictions, confidences = predict_naive_bayes(D_unsup, p_y, p_v_y)\n",
    "            idx = 0\n",
    "            for conf in confidences:              \n",
    "                if conf >= 0.98:               \n",
    "                    X_initial.append(X_unsup[idx])\n",
    "                    y_initial.append(predictions[idx])\n",
    "                    del X_unsup[idx]\n",
    "                    del D_unsup[idx]\n",
    "                idx += 0\n",
    "            len_new = len(X_initial)\n",
    "        predictions, confidences = predict_naive_bayes(D_valid, p_y, p_v_y)\n",
    "        final_accuracy = accuracy_score(y_valid, predictions)\n",
    "        print(\"final accuracy for valid: \"  + str(final_accuracy))\n",
    "        \n",
    "    # top k\n",
    "    if mode == \"top-k\":\n",
    "        p_y, p_v_y = train_naive_bayes(X_initial, y_initial, k, vocab)\n",
    "        predictions, confidences = predict_naive_bayes(D_unsup, p_y, p_v_y)\n",
    "        x_y = list(zip(X_unsup, predictions, confidences))\n",
    "        sort_x_y = sorted(x_y, key=lambda x: x[2], reverse=True)\n",
    "        top_k = sort_x_y[:10000]\n",
    "        X_add, y_add, conf = zip(*top_k)\n",
    "        X_add = list(X_add)\n",
    "        y_add = list(y_add)\n",
    "        X_initial.extend(X_add)\n",
    "        y_initial.extend(y_add)\n",
    "        p_y, p_v_y = train_naive_bayes(X_initial, y_initial, k, vocab)\n",
    "        predictions, confidences = predict_naive_bayes(D_valid, p_y, p_v_y)\n",
    "        final_accuracy = accuracy_score(y_valid, predictions)\n",
    "        print(\"final accuracy for valid: \"  + str(final_accuracy))\n",
    "\n",
    "    return p_y, p_v_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that are named D_* are lists of documents where each\n",
    "# document is a list of tokens. y_* is a list of integer class labels.\n",
    "# X_* is a list of the feature dictionaries for each document.\n",
    "D_train, y_train = load_dataset('data/train.jsonl')\n",
    "D_valid, y_valid = load_dataset('data/valid.jsonl')\n",
    "D_test, y_test = load_dataset('data/test.jsonl')\n",
    "\n",
    "vocab = get_vocabulary(D_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBoW\n",
      "k = 0.001 : 0.8524\n",
      "k = 0.01 : 0.8572\n",
      "k = 0.1 : 0.8616\n",
      "k = 1.0 : 0.8656\n",
      "k = 10.0 : 0.864\n",
      "CCoW\n",
      "k = 0.001 : 0.85\n",
      "k = 0.01 : 0.8552\n",
      "k = 0.1 : 0.8604\n",
      "k = 1.0 : 0.8616\n",
      "k = 10.0 : 0.8632\n",
      "TFIDF\n",
      "k = 0.001 : 0.8408\n",
      "k = 0.01 : 0.8452\n",
      "k = 0.1 : 0.8484\n",
      "k = 1.0 : 0.8504\n",
      "k = 10.0 : 0.8556\n"
     ]
    }
   ],
   "source": [
    "# Compute the features, for example, using the BBowFeaturizer.\n",
    "# You actually only need to conver the training instances to their\n",
    "# feature-based representations.\n",
    "# \n",
    "# This is just starter code for the experiment. You need to fill in\n",
    "# the rest.\n",
    "\n",
    "# 1.3 Navie Bayes Experiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "K = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "featurizer1 = BBoWFeaturizer()\n",
    "X_train1 = convert_to_features(D_train, featurizer1, vocab)\n",
    "X_test1 = convert_to_features(D_test, featurizer1, vocab)\n",
    "featurizer2 = CBoWFeaturizer()\n",
    "X_train2 = convert_to_features(D_train, featurizer2, vocab)\n",
    "X_test2 = convert_to_features(D_test, featurizer2, vocab)\n",
    "idf = compute_idf(D_train, vocab)\n",
    "featurizer3 = TFIDFFeaturizer(idf)\n",
    "X_train3 = convert_to_features(D_train, featurizer3, vocab)\n",
    "X_test3 = convert_to_features(D_test, featurizer3, vocab)\n",
    "# for BBoW:\n",
    "print(\"BBoW\")\n",
    "for k in K:\n",
    "    p_y, p_v_y = train_naive_bayes(X_train1, y_train, k, vocab)\n",
    "    predictions, confidences = predict_naive_bayes(X_test1, p_y, p_v_y)\n",
    "    acc = accuracy_score(y_test, predictions) \n",
    "    print(\"k = \" + str(k) + \" : \" + str(acc))\n",
    "# for CCoW:\n",
    "print(\"CCoW\")\n",
    "for k in K:\n",
    "    p_y, p_v_y = train_naive_bayes(X_train2, y_train, k, vocab)\n",
    "    predictions, confidences = predict_naive_bayes(X_test2, p_y, p_v_y)\n",
    "    acc = accuracy_score(y_test, predictions) \n",
    "    print(\"k = \" + str(k) + \" : \" + str(acc))\n",
    "# for TFIDF:\n",
    "print(\"TFIDF\")\n",
    "for k in K:\n",
    "    p_y, p_v_y = train_naive_bayes(X_train3, y_train, k, vocab)\n",
    "    predictions, confidences = predict_naive_bayes(X_test3, p_y, p_v_y)\n",
    "    acc = accuracy_score(y_test, predictions) \n",
    "    print(\"k = \" + str(k) + \" : \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBoW\n",
      "threshold:\n",
      "50:\n",
      "initial accuracy: 0.5284\n",
      "final accuracy: 0.5168\n",
      "final accuracy for test: 0.8556\n",
      "BBoW\n",
      "threshold:\n",
      "500:\n",
      "initial accuracy: 0.7544\n",
      "final accuracy: 0.4836\n",
      "final accuracy for test: 0.8556\n",
      "BBoW\n",
      "threshold:\n",
      "5000:\n",
      "initial accuracy: 0.8268\n",
      "final accuracy: 0.5444\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "50:\n",
      "initial accuracy: 0.5188\n",
      "final accuracy: 0.5168\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "500:\n",
      "initial accuracy: 0.7648\n",
      "final accuracy: 0.7524\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "5000:\n",
      "initial accuracy: 0.824\n",
      "final accuracy: 0.7796\n",
      "final accuracy for test: 0.8556\n",
      "---------------------------------------------------\n",
      "CCoW\n",
      "threshold:\n",
      "50:\n",
      "initial accuracy: 0.5776\n",
      "final accuracy: 0.5168\n",
      "final accuracy for test: 0.8556\n",
      "CCoW\n",
      "threshold:\n",
      "500:\n",
      "initial accuracy: 0.7848\n",
      "final accuracy: 0.5164\n",
      "final accuracy for test: 0.8556\n",
      "CCoW\n",
      "threshold:\n",
      "5000:\n",
      "initial accuracy: 0.826\n",
      "final accuracy: 0.5728\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "50:\n",
      "initial accuracy: 0.5944\n",
      "final accuracy: 0.6388\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "500:\n",
      "initial accuracy: 0.7528\n",
      "final accuracy: 0.7552\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "5000:\n",
      "initial accuracy: 0.8276\n",
      "final accuracy: 0.802\n",
      "final accuracy for test: 0.8556\n",
      "---------------------------------------------------\n",
      "TFIDF\n",
      "threshold:\n",
      "50:\n",
      "initial accuracy: 0.562\n",
      "final accuracy: 0.5172\n",
      "final accuracy for test: 0.8556\n",
      "TFIDF\n",
      "threshold:\n",
      "500:\n",
      "initial accuracy: 0.7172\n",
      "final accuracy: 0.5168\n",
      "final accuracy for test: 0.8556\n",
      "TFIDF\n",
      "threshold:\n",
      "5000:\n",
      "initial accuracy: 0.778\n",
      "final accuracy: 0.5092\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "50:\n",
      "initial accuracy: 0.6444\n",
      "final accuracy: 0.6016\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "500:\n",
      "initial accuracy: 0.7304\n",
      "final accuracy: 0.6816\n",
      "final accuracy for test: 0.8556\n",
      "top-k:\n",
      "5000:\n",
      "initial accuracy: 0.7932\n",
      "final accuracy: 0.714\n",
      "final accuracy for test: 0.8556\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Navie Bayes Experiment\n",
    "import random\n",
    "\n",
    "S = list(zip(D_train, y_train)) # zip for seperating easily\n",
    "Num = [50, 500, 5000] # num of initial instances\n",
    "\n",
    "# BBoW\n",
    "for num in Num:\n",
    "    print(\"BBoW\") \n",
    "    print(\"threshold:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "    \n",
    "    X_sup = convert_to_features(D_sup, featurizer1, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer1, vocab)\n",
    "    \n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"threshold\")\n",
    "    \n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    " \n",
    "    \n",
    "for num in Num:\n",
    "    print(\"top-k:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "\n",
    "    X_sup = convert_to_features(D_sup, featurizer1, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer1, vocab)\n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"top-k\")\n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    "print(\"---------------------------------------------------\")  \n",
    "\n",
    "# CCoW\n",
    "# BBoW\n",
    "for num in Num:\n",
    "    print(\"CCoW\") \n",
    "    print(\"threshold:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "    \n",
    "    X_sup = convert_to_features(D_sup, featurizer2, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer2, vocab)\n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"threshold\")\n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    "    \n",
    "for num in Num:\n",
    "    print(\"top-k:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "\n",
    "    X_sup = convert_to_features(D_sup, featurizer2, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer2, vocab)\n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"top-k\")\n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    "print(\"---------------------------------------------------\")  \n",
    "\n",
    "# TFIDF\n",
    "# BBoW\n",
    "for num in Num:\n",
    "    print(\"TFIDF\") \n",
    "    print(\"threshold:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "    \n",
    "    X_sup = convert_to_features(D_sup, featurizer3, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer3, vocab)\n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"threshold\")\n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    "    \n",
    "for num in Num:\n",
    "    print(\"top-k:\")\n",
    "    print(str(num) + \":\")\n",
    "    random.shuffle(S)\n",
    "    S1 = S[:num]\n",
    "    S2 = S[num:]\n",
    "    D_sup, y_sup = zip(*S1)\n",
    "    \n",
    "    D_sup = list(D_sup)\n",
    "    y_sup = list(y_sup)\n",
    "    \n",
    "    D_unsup, y_unsup = zip(*S2)\n",
    "    \n",
    "    D_unsup = list(D_unsup)\n",
    "    \n",
    "    # for threshold mode\n",
    "\n",
    "    X_sup = convert_to_features(D_sup, featurizer3, vocab)\n",
    "    X_unsup = convert_to_features(D_unsup, featurizer3, vocab)\n",
    "    p_y, p_v_y = train_semi_supervised(X_sup, y_sup, D_unsup, X_unsup, D_valid, y_valid, 0.1, vocab, \"top-k\")\n",
    "    # for test accuracy\n",
    "    predidctions, confidences = predict_naive_bayes(D_test, p_y, p_v_y)\n",
    "    final_accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"final accuracy for test: \"  + str(final_accuracy))\n",
    "    \n",
    "print(\"---------------------------------------------------\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
